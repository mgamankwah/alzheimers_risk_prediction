{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97eceeee-024a-4053-8256-cbfda994c50b",
   "metadata": {},
   "source": [
    "Date: 03/19/2025 \\\n",
    "Author: Nasheed Jafri \\\n",
    "Purpose: Initial model exploration for the alzheimers dataset from kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22865396-f9be-45a1-923c-853060feb2b3",
   "metadata": {},
   "source": [
    "# **Model Exploration**\n",
    "\n",
    "P.S. I tried to make things consistent with Seyed's notebook because I like how he structured his work. I explored the following models:\n",
    "\n",
    "- Stochastic Gradient Descent (GradientBoostingClassifier)\n",
    "- (Gaussian) Na«êve Bayes\n",
    "- Linear Discriminant Analysis\n",
    "- Quadratic Disciminant Analysis\n",
    "\n",
    "Each model is examined on various subcategories of features and the accuracy rates are compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa857476-ec4a-4e8d-8123-a6a5db14cb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1897b649-026e-41d0-b99c-61bcd4c2c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv(\"../data/kaggle_train.csv\")\n",
    "df = df.drop(columns=['DoctorInCharge', 'PatientID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "821f8a0e-305c-463d-b3d5-2c26c0ab32ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subfeature categories\n",
    "all_features = [   'Age', 'Gender', 'Ethnicity', 'EducationLevel', 'BMI',\n",
    "               'Smoking', 'AlcoholConsumption', 'PhysicalActivity', 'DietQuality',\n",
    "               'SleepQuality', 'FamilyHistoryAlzheimers', 'CardiovascularDisease',\n",
    "               'Diabetes', 'Depression', 'HeadInjury', 'Hypertension', 'SystolicBP',\n",
    "               'DiastolicBP', 'CholesterolTotal', 'CholesterolLDL', 'CholesterolHDL',\n",
    "               'CholesterolTriglycerides', 'MMSE', 'FunctionalAssessment',\n",
    "               'MemoryComplaints', 'BehavioralProblems', 'ADL', 'Confusion',\n",
    "               'Disorientation', 'PersonalityChanges', 'DifficultyCompletingTasks',\n",
    "               'Forgetfulness' , 'Diagnosis']\n",
    "demo_features = ['Age', 'Gender', 'Ethnicity','EducationLevel','Diagnosis']\n",
    "life_style_features = ['BMI','Smoking', 'AlcoholConsumption', 'PhysicalActivity', 'DietQuality', 'SleepQuality','Diagnosis']\n",
    "medic_hist_features = ['FamilyHistoryAlzheimers', 'CardiovascularDisease','Diabetes', 'Depression', 'HeadInjury', 'Hypertension','Diagnosis']\n",
    "clinical_features = ['SystolicBP','DiastolicBP', 'CholesterolTotal', 'CholesterolLDL', 'CholesterolHDL','CholesterolTriglycerides','Diagnosis']\n",
    "cognitive_features = ['MMSE', 'FunctionalAssessment','MemoryComplaints', 'BehavioralProblems', 'ADL','Diagnosis']\n",
    "symptoms_features = ['Confusion','Disorientation', 'PersonalityChanges', 'DifficultyCompletingTasks','Forgetfulness','Diagnosis']\n",
    "\n",
    "no_cognitive = [item for item in all_features if item not in cognitive_features]\n",
    "no_cognitive.append('Diagnosis')\n",
    "\n",
    "subcategory_dict = {'all_features' : all_features,'demo':demo_features ,'lifestyle': life_style_features , 'medic' : medic_hist_features , \n",
    "                    'clinical':clinical_features , 'cognitive': cognitive_features , 'symptoms': symptoms_features , 'no_cognitive': no_cognitive}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97d22d56-9da1-41d7-9868-f5086d6a17c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "df_train, df_test = train_test_split(df, random_state=123, shuffle=True, test_size=0.2, stratify=df['Diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd574794-e645-4a18-8c01-662bdc69a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Identify categorical and numerical features\n",
    "# categorical_features = df_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "# numerical_features = df_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "# categorical_features.remove('Diagnosis') if 'Diagnosis' in categorical_features else None\n",
    "# numerical_features.remove('Diagnosis') if 'Diagnosis' in numerical_features else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4553277-2c3e-4573-90fc-940167ce272e",
   "metadata": {},
   "source": [
    "## **Stochastic Gradient Descent (GradientBoostingClassifier)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ae69ea0-28d8-4373-be1c-12f4a08aa071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_features</th>\n",
       "      <th>demo</th>\n",
       "      <th>lifestyle</th>\n",
       "      <th>medic</th>\n",
       "      <th>clinical</th>\n",
       "      <th>cognitive</th>\n",
       "      <th>symptoms</th>\n",
       "      <th>no_cognitive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy Score</th>\n",
       "      <td>0.950581</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.639535</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.639535</td>\n",
       "      <td>0.633721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.925620</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.123967</td>\n",
       "      <td>0.917355</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.099174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.413793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.929461</td>\n",
       "      <td>0.116788</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.047244</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>0.932773</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.049419</td>\n",
       "      <td>0.351744</td>\n",
       "      <td>0.360465</td>\n",
       "      <td>0.351744</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.360465</td>\n",
       "      <td>0.366279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 all_features      demo  lifestyle     medic  clinical  \\\n",
       "Accuracy Score       0.950581  0.648256   0.639535  0.648256  0.625000   \n",
       "Precision Score      0.925620  0.066116   0.066116  0.024793  0.123967   \n",
       "Recall Score         0.933333  0.500000   0.421053  0.500000  0.394737   \n",
       "F1 Score             0.929461  0.116788   0.114286  0.047244  0.188679   \n",
       "MSE                  0.049419  0.351744   0.360465  0.351744  0.375000   \n",
       "\n",
       "                 cognitive  symptoms  no_cognitive  \n",
       "Accuracy Score    0.953488  0.639535      0.633721  \n",
       "Precision Score   0.917355  0.008264      0.099174  \n",
       "Recall Score      0.948718  0.200000      0.413793  \n",
       "F1 Score          0.932773  0.015873      0.160000  \n",
       "MSE               0.046512  0.360465      0.366279  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc_pipe = Pipeline([('scale', StandardScaler()), ('gbc', GradientBoostingClassifier(random_state=42))])\n",
    "\n",
    "gbc_accu_score = {}\n",
    "\n",
    "for key in subcategory_dict:\n",
    "    item = subcategory_dict[key]\n",
    "    gbc_pipe.fit(df_train[item[:-1]], df_train.Diagnosis)\n",
    "    pred = gbc_pipe.predict(df_test[item[:-1]])\n",
    "\n",
    "    gbc_accu_score[key] = [accuracy_score(pred, df_test.Diagnosis),\n",
    "                           precision_score(pred, df_test.Diagnosis, zero_division=1),\n",
    "                           recall_score(pred, df_test.Diagnosis),\n",
    "                           f1_score(pred, df_test.Diagnosis),\n",
    "                           mean_squared_error(pred, df_test.Diagnosis)]\n",
    "\n",
    "gbc_accu_score_df = pd.DataFrame(gbc_accu_score, index=['Accuracy Score', 'Precision Score', 'Recall Score', 'F1 Score', 'MSE'])\n",
    "gbc_accu_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e850437-0af6-45b8-8e35-19f1fa9f8424",
   "metadata": {},
   "source": [
    "**NOTE:** I performed a hyperparaneter tuning using GridSearchCV and strangely **got poorer results** than what I got above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2cfd11d-eaf6-4de2-a2e0-c07dc1bebf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_features</th>\n",
       "      <th>demo</th>\n",
       "      <th>lifestyle</th>\n",
       "      <th>medic</th>\n",
       "      <th>clinical</th>\n",
       "      <th>cognitive</th>\n",
       "      <th>symptoms</th>\n",
       "      <th>no_cognitive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy Score</th>\n",
       "      <td>0.941860</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.642442</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.642442</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.648256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.917355</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.917355</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.917355</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047244</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.058140</td>\n",
       "      <td>0.351744</td>\n",
       "      <td>0.357558</td>\n",
       "      <td>0.351744</td>\n",
       "      <td>0.357558</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.351744</td>\n",
       "      <td>0.351744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Learning Rate</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best n_estimators</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Max Depth</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    all_features       demo  lifestyle       medic   clinical  \\\n",
       "Accuracy Score          0.941860   0.648256   0.642442    0.648256   0.642442   \n",
       "Precision Score         0.917355   0.008264   0.000000    0.024793   0.074380   \n",
       "Recall Score            0.917355   0.500000   0.000000    0.500000   0.450000   \n",
       "F1 Score                0.917355   0.016260   0.000000    0.047244   0.127660   \n",
       "MSE                     0.058140   0.351744   0.357558    0.351744   0.357558   \n",
       "Best Learning Rate      0.200000   0.050000   0.050000    0.100000   0.100000   \n",
       "Best n_estimators      50.000000  50.000000  50.000000  100.000000  50.000000   \n",
       "Best Max Depth          3.000000   3.000000   3.000000    3.000000   3.000000   \n",
       "\n",
       "                     cognitive   symptoms  no_cognitive  \n",
       "Accuracy Score        0.953488   0.648256      0.648256  \n",
       "Precision Score       0.909091   0.000000      0.033058  \n",
       "Recall Score          0.956522   0.000000      0.500000  \n",
       "F1 Score              0.932203   0.000000      0.062016  \n",
       "MSE                   0.046512   0.351744      0.351744  \n",
       "Best Learning Rate    0.050000   0.050000      0.050000  \n",
       "Best n_estimators   100.000000  50.000000     50.000000  \n",
       "Best Max Depth        3.000000   3.000000      3.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WEIRD! GridSearch gave poorer results...??\n",
    "## WARNING: THE FOLLOWING CODE TAKES VERY LONG TO EXECUTE!!\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'gbc__learning_rate': [0.05, 0.1, 0.2],\n",
    "    'gbc__n_estimators': [50, 100],\n",
    "    'gbc__max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "# Initialize pipeline\n",
    "gbc_pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('gbc', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "gbc_accu_score = {}\n",
    "best_params_dict = {}\n",
    "\n",
    "for key in subcategory_dict:\n",
    "    item = subcategory_dict[key]\n",
    "    \n",
    "    # Perform GridSearchCV to find the best hyperparameters\n",
    "    grid_search = GridSearchCV(gbc_pipe, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(df_train[item[:-1]], df_train.Diagnosis)\n",
    "\n",
    "    # Best model from GridSearchCV\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Make predictions\n",
    "    pred = best_model.predict(df_test[item[:-1]])\n",
    "\n",
    "    # Store best hyperparameters\n",
    "    best_params_dict[key] = grid_search.best_params_\n",
    "\n",
    "    # Store accuracy scores\n",
    "    gbc_accu_score[key] = [\n",
    "        accuracy_score(pred, df_test.Diagnosis),\n",
    "        precision_score(pred, df_test.Diagnosis, zero_division=1),\n",
    "        recall_score(pred, df_test.Diagnosis),\n",
    "        f1_score(pred, df_test.Diagnosis),\n",
    "        mean_squared_error(pred, df_test.Diagnosis),\n",
    "        grid_search.best_params_['gbc__learning_rate'],\n",
    "        grid_search.best_params_['gbc__n_estimators'],\n",
    "        grid_search.best_params_['gbc__max_depth']\n",
    "    ]\n",
    "\n",
    "gbc_accu_score_df = pd.DataFrame(\n",
    "    gbc_accu_score, \n",
    "    index=['Accuracy Score', 'Precision Score', 'Recall Score', 'F1 Score', 'MSE', \n",
    "           'Best Learning Rate', 'Best n_estimators', 'Best Max Depth']\n",
    ")\n",
    "gbc_accu_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b938cea0-a398-4d21-95cc-6c1f25754f94",
   "metadata": {},
   "source": [
    "## **Gaussian Na«êve Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4819564c-d7d7-44fd-94e1-016ae96aa7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_features</th>\n",
       "      <th>demo</th>\n",
       "      <th>lifestyle</th>\n",
       "      <th>medic</th>\n",
       "      <th>clinical</th>\n",
       "      <th>cognitive</th>\n",
       "      <th>symptoms</th>\n",
       "      <th>no_cognitive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy Score</th>\n",
       "      <td>0.831395</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.633721</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.834302</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.613372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.778761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.752137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.168605</td>\n",
       "      <td>0.351744</td>\n",
       "      <td>0.351744</td>\n",
       "      <td>0.366279</td>\n",
       "      <td>0.351744</td>\n",
       "      <td>0.165698</td>\n",
       "      <td>0.351744</td>\n",
       "      <td>0.386628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 all_features      demo  lifestyle     medic  clinical  \\\n",
       "Accuracy Score       0.831395  0.648256   0.648256  0.633721  0.648256   \n",
       "Precision Score      0.727273  0.000000   0.000000  0.024793  0.000000   \n",
       "Recall Score         0.778761  0.000000   0.000000  0.272727  0.000000   \n",
       "F1 Score             0.752137  0.000000   0.000000  0.045455  0.000000   \n",
       "MSE                  0.168605  0.351744   0.351744  0.366279  0.351744   \n",
       "\n",
       "                 cognitive  symptoms  no_cognitive  \n",
       "Accuracy Score    0.834302  0.648256      0.613372  \n",
       "Precision Score   0.727273  0.000000      0.074380  \n",
       "Recall Score      0.785714  0.000000      0.300000  \n",
       "F1 Score          0.755365  0.000000      0.119205  \n",
       "MSE               0.165698  0.351744      0.386628  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the pipeline\n",
    "gnb_pipe = Pipeline([('scale', StandardScaler()), ('gnb', GaussianNB())])\n",
    "\n",
    "# Accuracy score for each subcategory of features\n",
    "gnb_accu_score = {}\n",
    "\n",
    "# Running the classifier through each subcategory\n",
    "for key in subcategory_dict:\n",
    "    item = subcategory_dict[key]\n",
    "    gnb_pipe.fit(df_train[item[:-1]], df_train.Diagnosis)\n",
    "    pred = gnb_pipe.predict(df_test[item[:-1]])\n",
    "    \n",
    "    gnb_accu_score[key] = [accuracy_score(pred, df_test.Diagnosis),\n",
    "                           precision_score(pred, df_test.Diagnosis, zero_division=1),\n",
    "                           recall_score(pred, df_test.Diagnosis),\n",
    "                           f1_score(pred, df_test.Diagnosis),\n",
    "                           mean_squared_error(pred, df_test.Diagnosis)]\n",
    "\n",
    "gnb_accu_score_df = pd.DataFrame(gnb_accu_score, index=['Accuracy Score', 'Precision Score', 'Recall Score', 'F1 Score', 'MSE'])\n",
    "gnb_accu_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ddc644-12cc-4a39-801f-6d22a4c57fac",
   "metadata": {},
   "source": [
    "## **Linear Discriminant Analysis (LDA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b8a1d74b-73d5-40e7-8437-30704b280526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_features</th>\n",
       "      <th>demo</th>\n",
       "      <th>lifestyle</th>\n",
       "      <th>medic</th>\n",
       "      <th>clinical</th>\n",
       "      <th>cognitive</th>\n",
       "      <th>symptoms</th>\n",
       "      <th>no_cognitive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy Score</th>\n",
       "      <td>0.843023</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.845930</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.645349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.791304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.771186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.768559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.156977</td>\n",
       "      <td>0.351744</td>\n",
       "      <td>0.351744</td>\n",
       "      <td>0.351744</td>\n",
       "      <td>0.351744</td>\n",
       "      <td>0.154070</td>\n",
       "      <td>0.351744</td>\n",
       "      <td>0.354651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 all_features      demo  lifestyle     medic  clinical  \\\n",
       "Accuracy Score       0.843023  0.648256   0.648256  0.648256  0.648256   \n",
       "Precision Score      0.752066  0.000000   0.000000  0.000000  0.000000   \n",
       "Recall Score         0.791304  0.000000   0.000000  0.000000  0.000000   \n",
       "F1 Score             0.771186  0.000000   0.000000  0.000000  0.000000   \n",
       "MSE                  0.156977  0.351744   0.351744  0.351744  0.351744   \n",
       "\n",
       "                 cognitive  symptoms  no_cognitive  \n",
       "Accuracy Score    0.845930  0.648256      0.645349  \n",
       "Precision Score   0.727273  0.000000      0.000000  \n",
       "Recall Score      0.814815  0.000000      0.000000  \n",
       "F1 Score          0.768559  0.000000      0.000000  \n",
       "MSE               0.154070  0.351744      0.354651  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_pipe = Pipeline([('scale', StandardScaler()), \n",
    "                     ('lda', LinearDiscriminantAnalysis())\n",
    "                    ])\n",
    "\n",
    "lda_accu_score = {}\n",
    "\n",
    "for key in subcategory_dict:\n",
    "    item = subcategory_dict[key]\n",
    "    lda_pipe.fit(df_train[item[:-1]], df_train.Diagnosis)\n",
    "    pred = lda_pipe.predict(df_test[item[:-1]])\n",
    "\n",
    "    lda_accu_score[key] = [accuracy_score(pred, df_test.Diagnosis),\n",
    "                           precision_score(pred, df_test.Diagnosis, zero_division=1),\n",
    "                           recall_score(pred, df_test.Diagnosis),\n",
    "                           f1_score(pred, df_test.Diagnosis),\n",
    "                           mean_squared_error(pred, df_test.Diagnosis)]\n",
    "\n",
    "lda_accu_score_df = pd.DataFrame(lda_accu_score, index=['Accuracy Score', 'Precision Score', 'Recall Score', 'F1 Score', 'MSE'])\n",
    "lda_accu_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2348be39-13c5-4807-ad70-6fbfc656758e",
   "metadata": {},
   "source": [
    "## **Quadratic Discriminant Analysis (QDA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8b981c98-e98f-40dd-92b9-8518f32db1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_features</th>\n",
       "      <th>demo</th>\n",
       "      <th>lifestyle</th>\n",
       "      <th>medic</th>\n",
       "      <th>clinical</th>\n",
       "      <th>cognitive</th>\n",
       "      <th>symptoms</th>\n",
       "      <th>no_cognitive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy Score</th>\n",
       "      <td>0.805233</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.636628</td>\n",
       "      <td>0.636628</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.848837</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.587209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.702479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.785124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.732759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.785124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.367089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.717300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>0.087591</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.785124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.194767</td>\n",
       "      <td>0.351744</td>\n",
       "      <td>0.363372</td>\n",
       "      <td>0.363372</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.151163</td>\n",
       "      <td>0.351744</td>\n",
       "      <td>0.412791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 all_features      demo  lifestyle     medic  clinical  \\\n",
       "Accuracy Score       0.805233  0.648256   0.636628  0.636628  0.651163   \n",
       "Precision Score      0.702479  0.000000   0.008264  0.049587  0.049587   \n",
       "Recall Score         0.732759  0.000000   0.166667  0.375000  0.545455   \n",
       "F1 Score             0.717300  0.000000   0.015748  0.087591  0.090909   \n",
       "MSE                  0.194767  0.351744   0.363372  0.363372  0.348837   \n",
       "\n",
       "                 cognitive  symptoms  no_cognitive  \n",
       "Accuracy Score    0.848837  0.648256      0.587209  \n",
       "Precision Score   0.785124  0.000000      0.239669  \n",
       "Recall Score      0.785124  0.000000      0.367089  \n",
       "F1 Score          0.785124  0.000000      0.290000  \n",
       "MSE               0.151163  0.351744      0.412791  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda_pipe = Pipeline([('scale', StandardScaler()), \n",
    "                     ('qda', QuadraticDiscriminantAnalysis())\n",
    "                    ])\n",
    "\n",
    "qda_accu_score = {}\n",
    "\n",
    "for key in subcategory_dict:\n",
    "    item = subcategory_dict[key]\n",
    "    qda_pipe.fit(df_train[item[:-1]], df_train.Diagnosis)\n",
    "    pred = qda_pipe.predict(df_test[item[:-1]])\n",
    "\n",
    "    qda_accu_score[key] = [accuracy_score(pred, df_test.Diagnosis),\n",
    "                           precision_score(pred, df_test.Diagnosis, zero_division=1),\n",
    "                           recall_score(pred, df_test.Diagnosis),\n",
    "                           f1_score(pred, df_test.Diagnosis),\n",
    "                           mean_squared_error(pred, df_test.Diagnosis)]\n",
    "\n",
    "qda_accu_score_df = pd.DataFrame(qda_accu_score, index=['Accuracy Score', 'Precision Score', 'Recall Score', 'F1 Score', 'MSE'])\n",
    "qda_accu_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9d3b7f-2691-467e-8f91-51c273c3a2b8",
   "metadata": {},
   "source": [
    "Since GaussianNB, LDA and QDA assume normally distributed features, I assumed it would perform worse. But it did surprisngly perform decently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f15dd-e0e6-46af-8a83-c5c0deaf1c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
